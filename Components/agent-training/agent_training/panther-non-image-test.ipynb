{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2020 Montvieux Ltd\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "import PIL.Image\n",
    "from IPython.display import display,clear_output,HTML\n",
    "from IPython.display import Image as DisplayImage\n",
    "import base64\n",
    "import json\n",
    "from io import StringIO\n",
    "import ipywidgets as widgets\n",
    "import sys\n",
    "import time\n",
    "import imageio\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "from stable_baselines.common.env_checker import check_env\n",
    "from stable_baselines.common.evaluation import evaluate_policy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv, VecNormalize\n",
    "from plark_game import classes\n",
    "from gym_plark.envs import plark_env,plark_env_guided_reward,plark_env_top_left,plark_env_sonobuoy_deployment, panther_env_reach_top\n",
    "\n",
    "from stable_baselines.bench import Monitor\n",
    "\n",
    "from stable_baselines import DQN, PPO2, A2C, ACKTR\n",
    "from stable_baselines.bench import Monitor\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "\n",
    "import helper \n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    div#notebook-container    { width: 95%; }\n",
       "    div#menubar-container     { width: 65%; }\n",
       "    div#maintoolbar-container { width: 99%; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    div#notebook-container    { width: 95%; }\n",
    "    div#menubar-container     { width: 65%; }\n",
    "    div#maintoolbar-container { width: 99%; }\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gym_plark.envs.plark_env:plark.kwargs :{'image_based': False, 'driving_agent': 'panther', 'render_height': 250, 'render_width': 310}\n",
      "INFO:gym_plark.envs.plark_env:self.image_based :False\n",
      "INFO:gym_plark.envs.plark_env:config filepath: /Components/plark-game/plark_game/game_config/10x10/balanced.json\n",
      "INFO:plark_game.classes.environment:Opening config from:/Components/plark-game/plark_game/game_config/10x10/balanced.json\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/pelicanAgent_5_buoys.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/PelicanAgentTestTurn.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/PelicanAgentIllegalMove.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/PantherAgentIllegalMove.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/pantherAgent_random_walk.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/PantherAgentTestTurn.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/pantherAgent_move_north.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/pelicanAgent_any_size_grid.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/pelicanAgent_3_buoys.py\n",
      "INFO:plark_game.classes.newgame:Opening agent from:/Components/plark-game/plark_game/agents/basic/__init__.py\n",
      "INFO:plark_game.classes.newgame:kwargs: {'image_based': False, 'driving_agent': 'panther', 'render_height': 250, 'render_width': 310}\n",
      "INFO:plark_game.classes.newgame:Playing against:Pelican_Agent_3_Bouys\n",
      "INFO:plark_game.classes.environment:Game Created\n",
      "INFO:plark_game.classes.observation:non-image observation space\n",
      "INFO:gym_plark.envs.plark_env:Non image observations created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kwargs\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "log_dir = './logs'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "env = panther_env_reach_top.PantherEnvReachTop(config_file_path='/Components/plark-game/plark_game/game_config/10x10/balanced.json',image_based=False)\n",
    "env = Monitor(env, log_dir)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "env = VecNormalize(env, norm_obs=True, norm_reward=False, clip_obs=200., gamma=0.95) \n",
    "#check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that the observations are indeed normalized\n",
    "# observation, reward, done, info = env.step([0])\n",
    "# np.set_printoptions(suppress=True)\n",
    "# np.set_printoptions(precision=3)\n",
    "# observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_eval_episodes = 10\n",
    "training_steps = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO2('MlpPolicy', env, seed=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines.ppo2.ppo2.PPO2 at 0x7f0be51b0198>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(training_steps)\n",
    "\n",
    "# for n in range(1000):\n",
    "    \n",
    "#     print(\"****** STARTING EVALUATION *******\")\n",
    "#     mean_reward, n_steps = evaluate_policy(model, \n",
    "#                                            env, \n",
    "#                                            n_eval_episodes=n_eval_episodes, \n",
    "#                                            deterministic=False, \n",
    "#                                            render=False, \n",
    "#                                            callback=None, \n",
    "#                                            reward_threshold=None, \n",
    "#                                            return_episode_rewards=False)\n",
    "#     print(\"****** EVALUATION FINISHED *******\")\n",
    "#     print(\"Mean Reward is \" + str(mean_reward))\n",
    "#     print(\"Number of steps is \" + str(n_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** STARTING EVALUATION *******\n",
      "****** EVALUATION FINISHED *******\n",
      "Mean Reward is -3.25\n",
      "Number of steps is 326\n"
     ]
    }
   ],
   "source": [
    "print(\"****** STARTING EVALUATION *******\")\n",
    "mean_reward, n_steps = evaluate_policy(model, env, n_eval_episodes=n_eval_episodes, deterministic=False, render=False, callback=None, reward_threshold=None, return_episode_rewards=False)\n",
    "print(\"****** EVALUATION FINISHED *******\")\n",
    "print(\"Mean Reward is \" + str(mean_reward))\n",
    "print(\"Number of steps is \" + str(n_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/agents/models/test_20210209_183129\n"
     ]
    }
   ],
   "source": [
    "#Save model \n",
    "basicdate = str(datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "\n",
    "basepath = '/data/agents/models'\n",
    "exp_name = 'test_' + basicdate\n",
    "exp_path = os.path.join(basepath, exp_name)\n",
    "\n",
    "print(exp_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DummyVecEnv' object has no attribute 'driving_agent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5f416924acea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodeltype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'PPO2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodelplayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriving_agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrender_height\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_height\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrender_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_width\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimage_based\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/stable_baselines/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mown_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocked_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetattr_recursive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_all_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/stable_baselines/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mgetattr_recursive\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvenv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetattr_recursive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# attribute not present, child is an unwrapped VecEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvenv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DummyVecEnv' object has no attribute 'driving_agent'"
     ]
    }
   ],
   "source": [
    "\n",
    "modeltype = 'PPO2'\n",
    "modelplayer = env.driving_agent \n",
    "render_height = env.render_height\n",
    "render_width = env.render_width\n",
    "image_based = False\n",
    "helper.save_model(exp_path,model,modeltype,modelplayer,render_height,render_width,image_based,basicdate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# making the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = '/test.mp4'\n",
    "basewidth,hsize = helper.make_video(model,env,video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = io.open(video_path, 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''<video alt=\"test\" width=\"'''+str(basewidth)+'''\" height=\"'''+str(hsize)+'''\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
